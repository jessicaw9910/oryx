{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c291eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load packages\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57ff690",
   "metadata": {},
   "source": [
    "# Import and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "632fe3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, url, url_bool = True):\n",
    "        ## URL if url_bool = True else file\n",
    "        self.url = url\n",
    "        self.url_bool = url_bool\n",
    "        ## names of items\n",
    "        self.list_name = []\n",
    "        ## status of items\n",
    "        self.list_status = []\n",
    "        ## total number of items\n",
    "        self.list_count = []\n",
    "        ## index of item for status\n",
    "        self.list_idx = []\n",
    "        ## link to confirmation\n",
    "        self.list_link = []\n",
    "    \n",
    "    def get_soup(self):\n",
    "        if self.url_bool:\n",
    "            page = requests.get(self.url)\n",
    "            self.soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        else:\n",
    "            with open(self.url, encoding=\"utf8\") as fp:\n",
    "                self.soup = BeautifulSoup(fp, 'html.parser')\n",
    "    \n",
    "    def get_tags(self):\n",
    "        ## needed for extract_info\n",
    "        li = self.soup.findAll('li')\n",
    "        self.list_total = [i.text.strip() for i in li if i.find('img', class_='thumbborder') is not None]\n",
    "        self.list_href = [i.findAll('a', href=True) for i in li if i.find('img', class_='thumbborder') is not None]\n",
    "        ## needed for add_groups\n",
    "        self.list_h3 = self.soup.findAll('h3')\n",
    "        self.list_tags = [tag.name for tag in self.soup.find_all(True)]\n",
    "        \n",
    "    def extract_info(self):\n",
    "        for idx, entry in enumerate(self.list_total):\n",
    "            ## take left of ':', remove leading/trailing space, split on first ' '\n",
    "            temp1 = entry.split(':')[0].strip().split(' ', 1)\n",
    "\n",
    "            ## turn string at front into int\n",
    "            try:\n",
    "                self.list_count.append(int(temp1[0]))\n",
    "            ## some have extra char, so take 1st str if so\n",
    "            except:\n",
    "                self.list_count.append(int(temp1[0][0]))\n",
    "\n",
    "            ## add item name\n",
    "            self.list_name.append(temp1[1])\n",
    "\n",
    "            ## take right of ':'\n",
    "            temp2 = entry.split(':')[1].strip()\n",
    "            ## take data between '()'\n",
    "            temp2 = re.findall('\\(.*?\\)',temp2)\n",
    "            ## split on last space to the right, remove '(' and ')'\n",
    "            temp2 = [i.replace('(', '').replace(')', '').rsplit(' ', 1) for i in temp2]\n",
    "            \n",
    "            count = []\n",
    "            status = []\n",
    "            link = []\n",
    "\n",
    "            for i, val in enumerate(temp2):\n",
    "                ## some numbers concatenated together so find all numbers\n",
    "                num = [int(s) for s in re.findall(r'\\s|,|[^,\\s]+', val[0]) if s.isdigit()]\n",
    "                count.extend(num)\n",
    "                ## get data after last space to the right\n",
    "                status.extend([val[1].strip()] * len(num))\n",
    "                ## add link to match the number of occurrences\n",
    "                try:\n",
    "                    link.extend([self.list_href[idx][i]['href']] * len(num))\n",
    "                except:\n",
    "                    print()\n",
    "                    print(idx)\n",
    "                    print(i)\n",
    "\n",
    "            self.list_idx.append(count)\n",
    "            self.list_status.append(status)\n",
    "            self.list_link.append(link)\n",
    "\n",
    "    def flatten_lists(self):\n",
    "        names = [[self.list_name[i]] * len(j) for i, j in enumerate(self.list_status)]\n",
    "        self.flat_name = [item for sublist in names for item in sublist]\n",
    "        self.flat_status = [item for sublist in self.list_status for item in sublist]\n",
    "        self.flat_index = [item for sublist in self.list_idx for item in sublist]\n",
    "        self.flat_link = [item for sublist in self.list_link for item in sublist]\n",
    "        self.flat_group = [item for sublist in self.list_groups for item in sublist]\n",
    "        self.flat_country = [item for sublist in self.list_countries for item in sublist]\n",
    "            \n",
    "    def add_groups(self):\n",
    "        ## find relative indices where text != '\\n'\n",
    "        idx_h3 = [m for m, n in enumerate(self.list_h3) if n.text != '\\n']\n",
    "        ## find text where text != '\\n'\n",
    "        name_h3 = [n.text for n in self.list_h3 if n.text != '\\n']\n",
    "\n",
    "        ## find all tags\n",
    "        ## absolute find index of all h3 tags\n",
    "        idx_tag = [idx for idx, tag in enumerate(self.list_tags) if tag == 'h3']\n",
    "        ## retain only absolute indices where text != '\\n'\n",
    "        idx_h3 = [idx_tag[i] for i in idx_h3]\n",
    "\n",
    "        ## find index of li tags\n",
    "        idx_li = [n for n, tag in enumerate(self.list_tags) if tag == 'li']\n",
    "\n",
    "        ## find text for all tags\n",
    "        text = [name.text for name in self.soup.find_all(True)]\n",
    "\n",
    "        ## find top-level tags where 'Russia' and 'Ukraine' occur\n",
    "        idx_rus = [i for i in idx_h3 if 'Russia' in text[i]][0]\n",
    "        idx_ukr = [i for i in idx_h3 if 'Ukraine' in text[i]][0]\n",
    "        \n",
    "        ## find all headings outside of those that contain 'Russia' and 'Ukraine'\n",
    "        categories = [text[i] for i in idx_h3 if i not in [idx_rus, idx_ukr]]\n",
    "        ## take info from heading before first '('\n",
    "        name_cat = [entry.split('(')[0].strip() for entry in categories]\n",
    "        \n",
    "        list_indices = []\n",
    "        list_country = []\n",
    "\n",
    "        for i in range(len(idx_h3) - 1):\n",
    "            if idx_h3[i] not in [idx_rus, idx_ukr]:\n",
    "                list_indices.append([idx for idx in idx_li if idx > idx_h3[i] and idx < idx_h3[i + 1]])\n",
    "                if idx_h3[i] > idx_ukr:\n",
    "                    list_country.append('UKR')\n",
    "                else:\n",
    "                    list_country.append('RUS')\n",
    "\n",
    "        ## for last entry\n",
    "        list_country.append('UKR')\n",
    "\n",
    "        idx_names = np.cumsum([len(i) for i in list_indices])\n",
    "\n",
    "        group_names = []\n",
    "\n",
    "        group_names.append(self.list_name[0:idx_names[0]])\n",
    "\n",
    "        for i in range(len(idx_names) - 1):\n",
    "            group_names.append(self.list_name[idx_names[i]:idx_names[i + 1]])\n",
    "\n",
    "        ## for last entry\n",
    "        last_entry = self.list_name[idx_names[-1]:-1]\n",
    "        last_entry.append(self.list_name[-1])\n",
    "        group_names.append(last_entry)\n",
    "        \n",
    "        i = 0\n",
    "\n",
    "        ## iterate over list count to get individual entries\n",
    "        self.list_groups = []\n",
    "        self.list_countries = []\n",
    "\n",
    "        for idx, groups in enumerate(group_names):\n",
    "            for group in groups:\n",
    "                self.list_groups.append([name_cat[idx]] * self.list_count[i])\n",
    "                self.list_countries.append([list_country[idx]] * self.list_count[i])\n",
    "                i += 1\n",
    "\n",
    "    def find_error(self):\n",
    "        list_range = []\n",
    "        for j in self.list_count:\n",
    "            list_range.append([i for i in range(1, j + 1)])\n",
    "\n",
    "        idx_wrong = []\n",
    "        for idx, entry in enumerate(list_range):\n",
    "            if entry != self.list_idx[idx]:\n",
    "                idx_wrong.append(idx)\n",
    "\n",
    "        for i in idx_wrong:\n",
    "            print(i)\n",
    "            print(self.list_total[i])\n",
    "            print(self.list_idx[i])\n",
    "            print(len(self.list_idx[i]))\n",
    "            print(self.list_count[i])\n",
    "            print()\n",
    "\n",
    "        return idx_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02b10fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.oryxspioenkop.com/2022/02/attack-on-europe-documenting-equipment.html'\n",
    "Oryx = Data(url)\n",
    "\n",
    "Oryx.get_soup()\n",
    "Oryx.get_tags()\n",
    "Oryx.extract_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dbe605",
   "metadata": {},
   "source": [
    "# Fix errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bbbf633",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_wrong = Oryx.find_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90a0f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fix errors\n",
    "Oryx.list_idx[83][4] = 5\n",
    "Oryx.list_idx[91][-1] = 2\n",
    "Oryx.list_idx[103][2] = 3\n",
    "Oryx.list_idx[103][3] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17d74e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "## remove 2 duplicates in entries\n",
    "n = 138\n",
    "temp_idx = []\n",
    "temp_status = []\n",
    "temp_link = []\n",
    "\n",
    "for i, j in enumerate(Oryx.list_idx[n]):\n",
    "    if j not in temp_idx:\n",
    "        temp_idx.append(j)\n",
    "        temp_status.append(Oryx.list_status[n][i])\n",
    "        temp_link.append(Oryx.list_link[n][i])\n",
    "    else:\n",
    "        print(j)\n",
    "\n",
    "Oryx.list_idx[n] = temp_idx\n",
    "Oryx.list_status[n] = temp_status\n",
    "Oryx.list_link[n] = temp_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aa959b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fix errors caused by duplicate numbers\n",
    "n = 218\n",
    "\n",
    "idx_wrong = [2, 4, 6, 8]\n",
    "\n",
    "Oryx.list_idx[n] = [j for i, j in enumerate(Oryx.list_idx[n]) if i not in idx_wrong]\n",
    "Oryx.list_status[n] = [j for i, j in enumerate(Oryx.list_status[n]) if i not in idx_wrong]\n",
    "Oryx.list_link[n] = [j for i, j in enumerate(Oryx.list_link[n]) if i not in idx_wrong]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cea0910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Oryx.find_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a68be40",
   "metadata": {},
   "source": [
    "# Add groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38f2fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Oryx.add_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94981d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Oryx.flatten_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aaca7d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(len(Oryx.flat_name))\n",
    "print(len(Oryx.flat_status))\n",
    "print(len(Oryx.flat_index))\n",
    "print(len(Oryx.flat_group))\n",
    "print(len(Oryx.flat_country))\n",
    "print(len(Oryx.flat_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a81ff974",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'name':Oryx.flat_name, \n",
    "                   'status':Oryx.flat_status, \n",
    "                   'idx': Oryx.flat_index, \n",
    "                   'group':Oryx.flat_group, \n",
    "                   'country':Oryx.flat_country, \n",
    "                   'link': Oryx.flat_link})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f272aa80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group                        country\n",
       "Trucks, Vehicles and Jeeps   UKR        12\n",
       "Radars                       UKR         5\n",
       "Infantry Fighting Vehicles   UKR         4\n",
       "Armoured Fighting Vehicles   RUS         2\n",
       "Infantry Mobility Vehicles   RUS         2\n",
       "Aircraft                     UKR         1\n",
       "Armoured Fighting Vehicles   UKR         1\n",
       "Armoured Personnel Carriers  UKR         1\n",
       "Helicopters                  RUS         1\n",
       "Infantry Mobility Vehicles   UKR         1\n",
       "Tanks                        RUS         1\n",
       "Trucks, Vehicles and Jeeps   RUS         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['group', 'country']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6039162b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tanks', 'Armoured Fighting Vehicles',\n",
       "       'Infantry Mobility Vehicles', 'Helicopters',\n",
       "       'Trucks, Vehicles and Jeeps', 'Infantry Fighting Vehicles',\n",
       "       'Armoured Personnel Carriers', 'Radars', 'Aircraft'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.group.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85ab1723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-24T122808Z\n"
     ]
    }
   ],
   "source": [
    "## save by datemod meta tag\n",
    "datemod = str(Oryx.soup.findAll('meta', itemprop=\"dateModified\", content=True))\n",
    "datemod = re.findall('\"([^\"]*)\"', datemod)[0].replace(':', '')\n",
    "print(datemod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b9038df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## output dataframe to CSV\n",
    "# cwd = os.getcwd()\n",
    "path = '../assets/' + datemod + '.csv'\n",
    "df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "622df690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-24T122808Z\n"
     ]
    }
   ],
   "source": [
    "print(datemod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6403db",
   "metadata": {},
   "source": [
    "# Process from archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a18a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../assets/wayback_machine/crawled/file_names.txt', encoding=\"utf8\") as file:\n",
    "    list_wayback = [line.strip() for line in file]\n",
    "    \n",
    "list_wayback = list_wayback[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37b078e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20220224123534.snapshot'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_wayback[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f68aba09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../assets/wayback_machine/crawled/20220316135717.snapshot'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "b4824c43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220224123534.snapshot\n",
      "2022-02-24T122808Z\n",
      "../assets/2022-02-24T122808Z.csv exists...\n",
      "20220224144043.snapshot\n",
      "2022-02-24T143801Z\n",
      "../assets/2022-02-24T143801Z.csv exists...\n",
      "20220224173139.snapshot\n",
      "2022-02-24T170304Z\n",
      "../assets/2022-02-24T170304Z.csv exists...\n",
      "20220224191858.snapshot\n",
      "2022-02-24T191637Z\n",
      "../assets/2022-02-24T191637Z.csv exists...\n",
      "20220224231142.snapshot\n",
      "2022-02-24T225309Z\n",
      "../assets/2022-02-24T225309Z.csv exists...\n",
      "20220225005420.snapshot\n",
      "2022-02-25T001319Z\n",
      "../assets/2022-02-25T001319Z.csv exists...\n",
      "20220225023717.snapshot\n",
      "2022-02-25T001319Z\n",
      "../assets/2022-02-25T001319Z.csv exists...\n",
      "20220225035215.snapshot\n",
      "2022-02-25T001319Z\n",
      "../assets/2022-02-25T001319Z.csv exists...\n",
      "20220225043350.snapshot\n",
      "2022-02-25T001319Z\n",
      "../assets/2022-02-25T001319Z.csv exists...\n",
      "20220225083745.snapshot\n",
      "2022-02-25T001319Z\n",
      "../assets/2022-02-25T001319Z.csv exists...\n",
      "20220225183832.snapshot\n",
      "2022-02-25T175042Z\n",
      "../assets/2022-02-25T175042Z.csv exists...\n",
      "20220225195302.snapshot\n",
      "2022-02-25T194828Z\n",
      "../assets/2022-02-25T194828Z.csv exists...\n",
      "20220225233528.snapshot\n",
      "2022-02-25T204508Z\n",
      "../assets/2022-02-25T204508Z.csv exists...\n",
      "20220226163127.snapshot\n",
      "2022-02-26T162937Z\n",
      "../assets/2022-02-26T162937Z.csv exists...\n",
      "20220226172301.snapshot\n",
      "2022-02-26T164106Z\n",
      "../assets/2022-02-26T164106Z.csv exists...\n",
      "20220226185336.snapshot\n",
      "2022-02-26T164106Z\n",
      "../assets/2022-02-26T164106Z.csv exists...\n",
      "20220227023709.snapshot\n",
      "2022-02-26T164106Z\n",
      "../assets/2022-02-26T164106Z.csv exists...\n",
      "20220227051603.snapshot\n",
      "2022-02-27T044102Z\n",
      "../assets/2022-02-27T044102Z.csv exists...\n",
      "20220227071652.snapshot\n",
      "2022-02-27T063601Z\n",
      "../assets/2022-02-27T063601Z.csv exists...\n",
      "20220227080755.snapshot\n",
      "2022-02-27T063601Z\n",
      "../assets/2022-02-27T063601Z.csv exists...\n",
      "20220227082518.snapshot\n",
      "2022-02-27T063601Z\n",
      "../assets/2022-02-27T063601Z.csv exists...\n",
      "20220227093545.snapshot\n",
      "2022-02-27T063601Z\n",
      "../assets/2022-02-27T063601Z.csv exists...\n",
      "20220227160720.snapshot\n",
      "2022-02-27T154221Z\n",
      "../assets/2022-02-27T154221Z.csv exists...\n",
      "20220227164733.snapshot\n",
      "2022-02-27T163851Z\n",
      "../assets/2022-02-27T163851Z.csv exists...\n",
      "20220227164947.snapshot\n",
      "2022-02-27T163851Z\n",
      "../assets/2022-02-27T163851Z.csv exists...\n",
      "20220227175728.snapshot\n",
      "2022-02-27T163851Z\n",
      "../assets/2022-02-27T163851Z.csv exists...\n",
      "20220227190823.snapshot\n",
      "2022-02-27T163851Z\n",
      "../assets/2022-02-27T163851Z.csv exists...\n",
      "20220227191915.snapshot\n",
      "2022-02-27T163851Z\n",
      "../assets/2022-02-27T163851Z.csv exists...\n",
      "20220227203412.snapshot\n",
      "2022-02-27T201504Z\n",
      "../assets/2022-02-27T201504Z.csv exists...\n",
      "20220227214345.snapshot\n",
      "2022-02-27T205519Z\n",
      "../assets/2022-02-27T205519Z.csv exists...\n",
      "20220228005724.snapshot\n",
      "2022-02-28T005227Z\n",
      "../assets/2022-02-28T005227Z.csv exists...\n",
      "20220228082741.snapshot\n",
      "2022-02-28T015933Z\n",
      "../assets/2022-02-28T015933Z.csv exists...\n",
      "20220228094824.snapshot\n",
      "2022-02-28T015933Z\n",
      "../assets/2022-02-28T015933Z.csv exists...\n",
      "20220228172138.snapshot\n",
      "2022-02-28T165204Z\n",
      "../assets/2022-02-28T165204Z.csv exists...\n",
      "20220228194432.snapshot\n",
      "2022-02-28T193511Z\n",
      "../assets/2022-02-28T193511Z.csv exists...\n",
      "20220228212123.snapshot\n",
      "2022-02-28T205610Z\n",
      "../assets/2022-02-28T205610Z.csv exists...\n",
      "20220228231717.snapshot\n",
      "2022-02-28T225506Z\n",
      "../assets/2022-02-28T225506Z.csv exists...\n",
      "20220228231935.snapshot\n",
      "2022-02-28T225506Z\n",
      "../assets/2022-02-28T225506Z.csv exists...\n",
      "20220301005336.snapshot\n",
      "2022-03-01T005118Z\n",
      "../assets/2022-03-01T005118Z.csv exists...\n",
      "20220301040227.snapshot\n",
      "2022-03-01T012041Z\n",
      "../assets/2022-03-01T012041Z.csv exists...\n",
      "20220301042956.snapshot\n",
      "2022-03-01T012041Z\n",
      "../assets/2022-03-01T012041Z.csv exists...\n",
      "20220301051804.snapshot\n",
      "2022-03-01T012041Z\n",
      "../assets/2022-03-01T012041Z.csv exists...\n",
      "20220301052826.snapshot\n",
      "2022-03-01T012041Z\n",
      "../assets/2022-03-01T012041Z.csv exists...\n",
      "20220301185329.snapshot\n",
      "2022-03-01T184736Z\n",
      "../assets/2022-03-01T184736Z.csv exists...\n",
      "20220302065331.snapshot\n",
      "2022-03-02T013029Z\n",
      "../assets/2022-03-02T013029Z.csv exists...\n",
      "20220302125110.snapshot\n",
      "2022-03-02T125041Z\n",
      "../assets/2022-03-02T125041Z.csv exists...\n",
      "20220302142653.snapshot\n",
      "2022-03-02T142109Z\n",
      "../assets/2022-03-02T142109Z.csv exists...\n",
      "20220302151016.snapshot\n",
      "2022-03-02T143545Z\n",
      "../assets/2022-03-02T143545Z.csv exists...\n",
      "20220302171331.snapshot\n",
      "2022-03-02T163622Z\n",
      "../assets/2022-03-02T163622Z.csv exists...\n",
      "20220302182006.snapshot\n",
      "2022-03-02T171946Z\n",
      "../assets/2022-03-02T171946Z.csv exists...\n",
      "20220302182714.snapshot\n",
      "2022-03-02T171946Z\n",
      "../assets/2022-03-02T171946Z.csv exists...\n",
      "20220302190116.snapshot\n",
      "2022-03-02T171946Z\n",
      "../assets/2022-03-02T171946Z.csv exists...\n",
      "20220302205559.snapshot\n",
      "2022-03-02T205108Z\n",
      "../assets/2022-03-02T205108Z.csv exists...\n",
      "20220303002812.snapshot\n",
      "2022-03-03T002748Z\n",
      "../assets/2022-03-03T002748Z.csv exists...\n",
      "20220303044108.snapshot\n",
      "2022-03-03T013203Z\n",
      "\n",
      "65\n",
      "7\n",
      "\n",
      "97\n",
      "73 KamAZ 6x6: (1, destroyed by Bayraktar TB2) (2, destroyed by Bayraktar TB2) (3 and 4, destroyed by Bayraktar TB2) (5, destroyed by Bayraktar TB2) (6, destroyed) (7, destroyed) (8, destroyed) (9, destroyed) (10, destroyed) (11, destroyed) (12, destroyed) (13, destroyed) (14, destroyed) (15, destroyed) (16, destroyed) (17, destroyed) (18, destroyed) (19, destroyed) (20, destroyed) (21, destroyed) (22, destroyed) (23 and 24, destroyed) (25, destroyed) (26, destroyed) (27, destroyed) (28, destroyed) (29, destroyed) (30, destroyed) (31, destroyed) (32, destroyed) (33, destroyed) (34, destroyed) (34, destroyed) (35, destroyed) (36, destroyed) (37, destroyed) (38, destroyed) (39, damaged) (40, damaged) (41, abandoned) (42, abandoned) (43, abandoned) (44, abandoned) (45, abandoned) (46, abandoned) (48, abandoned) (49, abandoned) (40 and 50, abandoned) (51, abandoned) (52, abandoned) (53, abandoned) (54, abandoned) (55, damaged and captured) (56, captured) (57, captured) (58, captured) (59, captured) (60 and 61, captured) (62, captured) (63, captured) (64, captured) (65 and 66, captured) (67, captured) (68, captured) (69, captured) (70 and 71, captured) (72, with ZU-23 AA gun, captured) (73, with ZU-23 AA gun, captured)\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 40, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]\n",
      "74\n",
      "73\n",
      "\n",
      "104\n",
      "1 BRM-1K: (1, damaged and captured) (2, captured)\n",
      "[1, 2]\n",
      "2\n",
      "1\n",
      "\n",
      "134\n",
      "2 9K35 Strela-10: (1, destroyed)\n",
      "[1]\n",
      "1\n",
      "2\n",
      "\n",
      "[97, 104, 134]\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "for name in list_wayback:\n",
    "\n",
    "    print(name)\n",
    "    file = '../assets/wayback_machine/crawled/' + name\n",
    "    Oryx = Data(file, url_bool=False)\n",
    "\n",
    "    Oryx.get_soup()\n",
    "\n",
    "    ## save by datemod meta tag\n",
    "    datemod = str(Oryx.soup.findAll('meta', itemprop=\"dateModified\", content=True))\n",
    "    datemod = re.findall('\"([^\"]*)\"', datemod)[0].replace(':', '')\n",
    "    print(datemod)\n",
    "\n",
    "    path = '../assets/' + datemod + '.csv'\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        print('{0} exists...'.format(path))\n",
    "        continue\n",
    "    else:\n",
    "        Oryx.get_tags()\n",
    "        Oryx.extract_info()\n",
    "        print()\n",
    "        idx_wrong = Oryx.find_error()\n",
    "        print(idx_wrong)\n",
    "        \n",
    "    temp = input()\n",
    "    if temp == 'stop':\n",
    "        break\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    Oryx.add_groups()\n",
    "    Oryx.flatten_lists()\n",
    "    \n",
    "    print(len(Oryx.flat_name))\n",
    "    print(len(Oryx.flat_status))\n",
    "    print(len(Oryx.flat_index))\n",
    "    print(len(Oryx.flat_group))\n",
    "    print(len(Oryx.flat_country))\n",
    "    print(len(Oryx.flat_link))\n",
    "    print()\n",
    "    \n",
    "    temp = input()\n",
    "    if temp == 'stop':\n",
    "        break\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    df = pd.DataFrame({'name':Oryx.flat_name, \n",
    "                       'status':Oryx.flat_status, \n",
    "                       'idx': Oryx.flat_index, \n",
    "                       'group':Oryx.flat_group, \n",
    "                       'country':Oryx.flat_country, \n",
    "                       'link': Oryx.flat_link})\n",
    "    \n",
    "    df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "55347d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://i.postimg.cc/8c0jfFn1/b6.png\">(1, destroyed)</a>,\n",
       " <a href=\"https://i.postimg.cc/B65zvHbK/b6.png\">(2 and 3, destroyed)</a>,\n",
       " <a href=\"https://i.postimg.cc/x16gjzR1/442.png\">(4, destroyed)</a>,\n",
       " <a href=\"https://i.postimg.cc/1t68G6Ls/Screenshot-8400.png\">(6, abandoned)</a>,\n",
       " <a href=\"https://i.postimg.cc/s2wR9DPH/768.png\">(7, damaged and captured)</a>,\n",
       " <a href=\"https://i.postimg.cc/xCF0twG5/b6.png\">(8, captured)</a>,\n",
       " <a href=\"https://i.postimg.cc/DZ0Q5pHc/6652.png\">(9, 10 and 11, captured)</a>]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Oryx.list_href[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "d9c10f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "Oryx.list_link[65].insert(4, 'NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "c71095b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Oryx.list_link[65].extend([Oryx.list_link[65][-1]] * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "0befda1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Oryx.list_link[65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "414327ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "## remove 2 duplicates in entries\n",
    "n = 97\n",
    "temp_idx = []\n",
    "temp_status = []\n",
    "temp_link = []\n",
    "\n",
    "for i, j in enumerate(Oryx.list_idx[n]):\n",
    "    if j not in temp_idx:\n",
    "        temp_idx.append(j)\n",
    "        temp_status.append(Oryx.list_status[n][i])\n",
    "        temp_link.append(Oryx.list_link[n][i])\n",
    "    else:\n",
    "        print(j)\n",
    "\n",
    "# Oryx.list_idx[n] = temp_idx\n",
    "# Oryx.list_status[n] = temp_status\n",
    "# Oryx.list_link[n] = temp_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "b9012f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Oryx.list_count[97] = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a8648ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Oryx.list_count[104] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "95bb0ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Oryx.list_count[134] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "50f09440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "73 KamAZ 6x6: (1, destroyed by Bayraktar TB2) (2, destroyed by Bayraktar TB2) (3 and 4, destroyed by Bayraktar TB2) (5, destroyed by Bayraktar TB2) (6, destroyed) (7, destroyed) (8, destroyed) (9, destroyed) (10, destroyed) (11, destroyed) (12, destroyed) (13, destroyed) (14, destroyed) (15, destroyed) (16, destroyed) (17, destroyed) (18, destroyed) (19, destroyed) (20, destroyed) (21, destroyed) (22, destroyed) (23 and 24, destroyed) (25, destroyed) (26, destroyed) (27, destroyed) (28, destroyed) (29, destroyed) (30, destroyed) (31, destroyed) (32, destroyed) (33, destroyed) (34, destroyed) (34, destroyed) (35, destroyed) (36, destroyed) (37, destroyed) (38, destroyed) (39, damaged) (40, damaged) (41, abandoned) (42, abandoned) (43, abandoned) (44, abandoned) (45, abandoned) (46, abandoned) (48, abandoned) (49, abandoned) (40 and 50, abandoned) (51, abandoned) (52, abandoned) (53, abandoned) (54, abandoned) (55, damaged and captured) (56, captured) (57, captured) (58, captured) (59, captured) (60 and 61, captured) (62, captured) (63, captured) (64, captured) (65 and 66, captured) (67, captured) (68, captured) (69, captured) (70 and 71, captured) (72, with ZU-23 AA gun, captured) (73, with ZU-23 AA gun, captured)\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]\n",
      "72\n",
      "72\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[97]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Oryx.find_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "c6e1a0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[47]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(1, 73) if i not in Oryx.list_idx[97]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "b6e6239f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713\n",
      "713\n",
      "713\n",
      "713\n",
      "713\n",
      "713\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Oryx.add_groups()\n",
    "Oryx.flatten_lists()\n",
    "\n",
    "print(len(Oryx.flat_name))\n",
    "print(len(Oryx.flat_status))\n",
    "print(len(Oryx.flat_index))\n",
    "print(len(Oryx.flat_group))\n",
    "print(len(Oryx.flat_country))\n",
    "print(len(Oryx.flat_link))\n",
    "print()\n",
    "\n",
    "temp = input()\n",
    "if temp == 'stop':\n",
    "    print(temp)\n",
    "else:\n",
    "    df = pd.DataFrame({'name':Oryx.flat_name, \n",
    "                       'status':Oryx.flat_status, \n",
    "                       'idx': Oryx.flat_index, \n",
    "                       'group':Oryx.flat_group, \n",
    "                       'country':Oryx.flat_country, \n",
    "                       'link': Oryx.flat_link})\n",
    "\n",
    "    df.to_csv(path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
